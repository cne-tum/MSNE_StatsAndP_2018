{\Large Lecturer: Prof. Dr. Bethge}\\[1cm]

\textbf{Examples of unsupervised learning applications}
\begin{itemize}
	\item \emph{density estimation} (e.g. texture synthesis), image compression
	\item level set estimation
	\item clustering/mode finding e.g. spike sorting; algorithm Mixture of Gaussians
	\item metric learning e.g. 3D visualization; algorithm multidimensional scaling
	\item feature extraction -> representation learning, e.g. whitening; algorithm principle component analysis
\end{itemize}

\section{Set algebras, measures, and probabilities}
\begin{itemize}
\item {\bf Overview for the mathematical construction of random variables}
\begin{itemize}
\item Sample Space $S$ (often also $\Omega $). $s\in S$ ``outcomes''
\item Boolean Algebra (or Sigma Algebra)  $\mathcal{B}(S)$ and $A \in \mathcal{B}(S)$ are called ``events''. An event $A$ is realized if an outcome $s$ is in $A$. \\For example, $\mathcal{B}(S)=\mathcal{P}(S)$
\item Measure $m: \mathcal{B}(S) \to [0,\infty)$ and $m(A\dot\cup B) = m(A) + m(B)$
\item probability measure $p(S)=1$, if $m$ is a measure with $m(S)<\infty$ then $p(A) := m(A)/m(S)$ is a probability measure.
\item random variables: consider $M \in \mathcal{B}(S)$ with $M=\{s \in S: X(s) < \vartheta\} \subseteq S$
\end{itemize}

\item {\bf Power Set:}  $\mathcal{P}(S) := \{A\subseteq S\}$, $|\mathcal{P}(S) |= 2^{|S|}$

\item {\bf Boolean Algebra:}  $\mathcal{B}(S) \subseteq \mathcal{P}(S)$ is called a {\it Boolean Algebra} iff
\begin{itemize}
\item[(i)] $A \in \mathcal{B}(S)  \Rightarrow \overline{A} \in \mathcal{B}(S)  $
\item[(ii)] $A, B \in \mathcal{B}(S)  \Rightarrow A \cup B \in \mathcal{B}(S)  $ 
\end{itemize}
Examples:
\begin{itemize}
\item[(i)] $\{ \emptyset, S\}  $ and $\mathcal{P}(S)$ are Boolean Algebras.
\item[(ii)] If $a\in S$ then $\{\emptyset, \{a\}, S-\{a\}, S\}$ is the Boolean Algebra {\it generated by} $a$.
\item[(iii)] $I(R)$ is defined to be the smallest Boolean Algebra which contains all open intervals $(a,b)$ for which $-\infty \le a < b\le \infty$. 
\end{itemize}

\item {\bf Sigma-Algebra:}  $\mathcal{B}(S) \subseteq \mathcal{P}(S)$ is called a Sigma-Algebra if  
\begin{itemize}
\item[(i)] $A \in \mathcal{B}(S)  \Rightarrow \overline{A} \in \mathcal{B}(S)  $
\item[(ii)] For all sequences $A_1, A_2, \dots \in \mathcal{B}(S)  \Rightarrow \bigcup_{k=1}^\infty A_k \in \mathcal{B}(S)  $ 
\end{itemize}

\item {\bf Venn diagram} 

\end{itemize}

%\item {\bf Proposition 1 (Boolean laws):} 
\begin{proposition}[Boolean laws]
\begin{itemize}
\item[(B1)] Idempotency: $A \cup A = A$;   \hspace{.5cm} $A \cap A = A$
\item[(B2)] Associativity: $A \cap (B\cap C) = (A\cap B) \cap C$  
\item[(B3)] Commutativity: $A \cup B = B \cup A$;    \hspace{.5cm}  $A \cap B = B \cap A$
\item[(B4)] Distributivity: $A \cap (B\cup C)  = (A \cap B) \cup (A \cap C)$; \hspace{.5cm}  $A \cup (B\cap C)  = (A \cup B) \cap (A \cup C)$
\item[(B5)] de Morgan's law:  $\overline{A \cup B} = \overline{A} \cap \overline{B} $;    \hspace{.5cm}  $\overline{A \cap B} = \overline{A} \cup \overline{B} $
\item[(B6)] Complements: $ \overline{ \overline{A}} =  A$; \hspace{.5cm}  $A \cap \overline{A} = \emptyset$; \hspace{.5cm}  $A \cup \overline{A} = S$
\item[(B7)] Properties of $S$ and $ \emptyset$: \hspace{.2cm} $A \cup S = S$; \hspace{.5cm} $A \cup \emptyset = A$; \hspace{.5cm} $A \cap S = A$; \hspace{.5cm} $A \cap \emptyset = \emptyset$

\end{itemize}
\end{proposition}

\begin{itemize}

\item {\bf (Finite) Measure:} A mapping $m: \mathcal{B}(S) \rightarrow [0, \infty), A\in  \mathcal{B}(S) \to m(A) \in [0, \infty)$ is called a {\it measure} if for all $A,B \in \mathcal{B}(S)$ with $A\cap B = \emptyset$ holds: $m(A\cup B) = m(A) + m(B)$.\\(This property can be written compactly as $m(A\dot\cup B) = m(A) + m(B)$)

Examples:
\begin{itemize}
\item[(i)] $m(A) := |A|$ is the {\it counting measure}.
\item[(ii)] For $S=[a,b]$ and $\mathcal{B}(S)=\mathcal{I}([a,b])$ with $|a|, |b| < \infty$ the {\it Lebesgue Measure} is defined as $m([c, d]) := d-c$.
\item[(iii)] If $f(x) \ge 0$ for all $a \le x \le b$ with $\int_a^b f(x) dx <\infty$ then $m([c, d]) := \int_c^d f(x) dx $ is a measure.
\item[(iv)] For $S=R$ and $\mathcal{B}(S)=\mathcal{I}(R)$ the {\it Dirac Ma\ss} is given by $\delta_a(J) = 1$ if $a\in J$ and $\delta_a(J) = 0$ otherwise.
\end{itemize}

\item {\bf Proposition 2:} 
\begin{itemize}
\item[(i)] If $B\subseteq A$ then $m(A-B) = m(A) - m(B)$.
\item[(ii)] If $B\subseteq A$ then $m(B) \le m(A)$.
\item[(iii)] $m(\emptyset) =0$.
\item[(iv)] $m(A \cup B) = m(A) + m(B) - m(A\cap B)$.
\end{itemize}

\item {\bf Proposition 3:}\\
If $A,B \in \mathcal{B}(S)$ then:
\begin{itemize}
\item[(i)] $ (A \cap B) \in \mathcal{B}(S)$ since $ (A \cap B) = \overline{\overline{A} \cup \overline{B}}$.
\item[(ii)] $\emptyset, S$ belong to every Boolean Algebra, since for $A \in \mathcal{B}(S)$ also $\overline{A} \in \mathcal{B}(S)$ and $A \cap \overline{A} = \emptyset$ and $A\cup \overline{A} = S$ .
\item[(iii)] $\mathcal{B}_B(S) := B \cap \mathcal{B}(S) = \{A \cap B: A \in \mathcal{B}(S)\}$ is a Boolean Algebra if $B\ne \emptyset$.
\item[(iv)] $\mathcal{B}_B(S) \subseteq \mathcal{B}(S)$. 
\end{itemize}


\item {\bf Probability measure:} For a sample space $S$ and a Sigma Algebra $\mathcal{B}(S)$ a measure \, $P$ is a {\it probability measure} if $P(S)=1$.

\item {\bf Probability space:} A probability space consists of the triple $(S,\mathcal{B}(S), P)$ where $S$ is the sample space, $\mathcal{B}(S)$ the event algebra (which is a Boolean or a sigma algebra) and $P$ is a  probability measure on $\mathcal{B}(S)$. 

\item {\bf Proposition 4:} 
\begin{itemize}
\item[(i)] $0 \le P(A) \le 1$.
\item[(ii)] $P(\overline{A}) = 1-P(A)$.
\item[(iii)] If $\mathcal{E}= \{E_1, E_2, \dots, E_n\}$ is a partition of $S$ (that is $S= \bigcup_{k=1}^n E_k$ and $E_l \cap E_m = \emptyset$), then \quad $\sum_{k=1}^n P(E_k) = 1$ \quad and \quad $P(A)=\sum_{k=1}^n P(A\cap E_k)$.
\end{itemize}

\item {\bf Specification of probabilities}
\begin{itemize}
\item[(i)] As a limiting value of relative frequencies: $P(A) = \lim_{n\to \infty} \frac{r_n(A)}{n}$
\item[(ii)] Symmetrie assumptions (e.g. if we assume $P(s)=P(s^\prime)$ for all $s,s^\prime \in S$ then it follows: $P(s) = 1/|S|$).
\item[(iii)] Subjective probabilities (based on Cox axioms) can be determined via betting games.
\end{itemize}
\item {\bf Conditional probabilities:}
If $(S,\mathcal{B}(S), P)$ is a probability space and $B \in \mathcal{B}(S)$ then the restriction of $P$ to the reduced Sigma-Algebra $\mathcal{B}_B(S):=\{B\cap A: A \in \mathcal{B}(S)\}$ defines a measure \ $M_B: \mathcal{B}_B \to [0,\infty)$. If in addition $P(B) >0$, then $P_B: \mathcal{B}_B(S) \to [0,1], \quad A_B \mapsto P_B(A_B) :=  M_B(A_B)/P(B)=P(A_B)/P(B), \, \forall A_B \in \mathcal{B}_B(S)$ is a probability measure on $\mathcal{B}_B(S)$.\\
The $A_B\in \mathcal{B}_B(S)$ usually originate from intersection of the elements of the original Sigma-Algebra $\mathcal{B}(S)$ with the event $B$.
\item {\bf Independence:}\\
Two events $A$ and $B$ are {\it statistically independent} iff $P(A\cap B) = P(A) P(B)$.
\item {\bf Proposition 5:} 
\begin{itemize}
\item[(i)] Two events $A$ and $B$ are (statistically) independent if $P(A)=0$ or $P(B)=0$.
\item[(ii)] If two events $A$ and $B$ are independent and $P(A)>0$, then: $P(B|A)=P_A(B)=P(B)$.
\item[(iii)] If two events $A$ and $B$ are independent and $P(A)>0$, then $A$ and $\overline{B}$ are independent as well.
\end{itemize}

\end{itemize}

\section{Random Variables}
\begin{itemize}
\item {\bf Cumulative distribution function (cdf):} 
Any univariate random variable can be uniquely defined by the cumulative distribution function:
$$
F(x) = P(\{s \in S: X(s) \le x\}), \quad \forall x \in S^\prime
$$
It holds:
\begin{itemize}
\item[(i)] $F$ is a nondecreasing function.
\item[(ii)] $\lim_{x\to -\infty} F(x)= 0$, $\lim_{x\to \infty} F(x)= 1$
\item[(iii)] Any function that fulfills (i)+(ii) is a cdf.
\item[(iv)] $ P(\{s \in S: X(s) > x\}) = 1-F(x)$
\item[(v)] $ P(\{s \in S: x_1 < X(s) \le x_2\}) = F(x_2)-F(x_1)$
\item[(vi)] discrete case: probability mass function / point probability $p(x) = F(x) - \lim_{\epsilon \to 0}F(x-\epsilon)$
\item[(vii)] continuous case: probability density function (pdf) $\rho(x) = \frac{d}{dx} \mathcal{F}(x)$
\end{itemize}


\item {\bf Expectation (value):} 
$$
E[X] = \sum_{k=1}^n p(x_k) x_k , \quad E[f(X)] = \sum_{k=1}^n p(x_k) f(x_k) 
$$
\item {\bf Moments:} 
$$
E[X^m] =  \sum_{k=1}^n p(x_k) x_k^m
$$
\item {\bf Variance:} 
$$
Var[X]= E[X^2]-E[X]^2
$$

\end{itemize}
\vfil 


