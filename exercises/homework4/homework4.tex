\documentclass{exam}

\usepackage{amsmath}

\usepackage{amssymb}

\usepackage{graphicx}


\usepackage{hyperref}

\pagestyle{headandfoot}
\runningheadrule
\firstpageheader{Machine Learning I}{Homework 4}{XY XY, 2012}

\title{Homework 4: Bayesics of Inference}
\date{}
\begin{document}
\maketitle
\thispagestyle{headandfoot}

\begin{center}
  {\fbox{\parbox{5.5in}{\centering
Solutions to this exercise sheet are to be handed in
 before the lecture on Wednesday, XY.XY.12. Code (.m-file) and output (.mat-file, figures as .pdf-files) for the  matlab-questions should be either submitted by email to \texttt{XY.XY@student.uni-tuebingen.de} (subject: [ML1] Exercise 4) or uploaded to Ilias. Use comments to explain your code. Please adhere to the file naming convention: \texttt{Homework4\_<YourName>.<ext>}.}}}
\end{center}
\vspace{.5cm}

This exercise sheet will concentrate on the Poisson distribution, which is a very important model in neuroscience. The Poisson distribution $P(X=x|\theta)$ denotes the probability of $x$ events happening in some observation interval (e.g. the number of action potentials fired by a neuron in response to a stimulus), assuming that these events happen at random times and with a mean rate of  $\theta$. We have
\begin{align}
P(X=x|\theta)&=\frac{1}{x!} \theta^x \exp(-\theta)%\\
%\mbox{E}(K|\theta)&= \theta\\
%\mbox{Var}(K|\theta)&= \theta\\
\end{align}


\begin{questions}
\question[15]{\bf Inference of the mean rate in the Poisson distribution}
~
 \begin{parts}
 \part Suppose you are given data ${x_1, x_2, \ldots x_N}.$ Show that the maximum likelihood estimate of $\theta$ is given by $\hat \theta=\frac{1}{N}\sum_n x_n$ [Hint: maximize the log-likelihood by setting its derivative w.r.t to $\theta$ to zero. You are not required to show that this is a maximum (rather than a minimum or stationary point).]
 
 \part Show that the Poisson distribution is in the exponential family, by identifying the functions $g(\theta)$, $f(x)$, $\phi(\theta)$ and $S(x)$ discussed in the lecture.
 
 \part The conjugate prior of the Poisson distribution is the Gamma distribution with parameters $\alpha$ and $\beta$, $\mbox{Gamma}(\alpha, \beta)$, 
 \begin{align}
 p(\theta| \alpha, \beta)=\frac{\beta^\alpha}{\Gamma(\alpha)}\theta^{\alpha-1}\exp(-\beta \theta) 
 \end{align}
 and mean $\mbox{E}(\theta)=\alpha/\beta$ and variance $\mbox{Var}(\theta)=\alpha/beta^2$.
Show that the posterior distribution over $\theta$ after observing data $D=\{x_1, x_2, x_3, \ldots x_n\}$ is given by
\begin{align}
\theta | D \sim \mbox{Gamma}(\alpha+\sum_{n=1}^N x_n, \beta+N)
\end{align}
 
 \end{parts}



\question[15] {\bf Inference in the Poisson distribution, Application [MATLAB]  }
\begin{parts}
\part Load the variables in the file \texttt{Homework2.mat}. Assuming that these data are generated by a Poisson distribution with parameter $\theta$, and using a Gamma-distribution with parameters $\alpha=2$ and $\beta=1$, calculate and plot the posterior distribution over $\theta$. [You do not need the statistics toolbox, but if you use the function \texttt{gampdf} in it , please note that it uses a different parameterization of the gamma distribution.] 
\part Calculate both the MLE and the posterior mean for $\theta$ using only the first $n$ datapoints, and plot both as a function of $n$. Report the MLE and the posterior mean of $\theta$ for $n=10$.
\part Plot the posterior variance as a function of $n$, and report the value for $n=10$.
\part ~[optional] Calculate the predictive distribution for the $n+1$th observation, and (numerically or analytically) calculate its mean and variance.

\end{parts}

\end{questions}




\end{document}